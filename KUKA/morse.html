<!DOCTYPE html>

<meta charset="utf-8">
<title>MORSE - The Modular OpenRobots Simulation Engine</title>
<link href="../media/js/prettify/prettify.css" type="text/css" rel="stylesheet" />
<script type="text/javascript" src="../media/js/prettify/prettify.js"></script>

<section>
    <h1>Introducing MORSE and myself<br/></h1>
    <footer>
    <img style="float:left; margin:0px;width:auto;height:70px" src="../media/logos/tum.svg"/>
    Michael Karg<br /> October 2013</footer>
</section>

<section>
	<figure>
        <video muted style="left:0px" src="../media/videos/morse-1.0.webm#t=7"></video> 
    </figure>
    <details>
    <ul>
        <li>MORSE video for the 1.0 release, in Feb. 2013</li>
        <li>Lasts 1'42"</li>
        <li>MORSE based on the open-source projects Blender, Bullet and Python</li>
        <li>Blender primary a 3D modeller, provides a 3D game engine (with support of shaders)</li>
    	<li>BGE: written in C++, extensible in Python + logic bricks</li>
		<li>Bullet integrated in BGE, state-of-the art open-source library</li>
        <li>support for rigid bodies and soft bodies simulation</li>
        <li>It has a human avator which you can control like in 3D computer games for HRI</li>
    </ul>
    </details>
</section>

<section>
    <h2>Presentation outline</h2>
    <ul>
      <li>The MORSE simulator
		<!--ul>
      		<li>Simulating with MORSE
      		<li>MORSE Principles
      		<li>Human-Robot Interaction
      		<li>Distributed simulations
      		<li>Still missing...
		</ul-->
	  <li>Low Cost Activity Recognition
		<!--ul>
			<li>A General Framework for expectations
			<li>Simulated Application Scenarios
			<li>Low Cost Activity Recognition
			<li>Real World Application 
		</ul-->
	  <li>Student Project: HRI Interface for B21
    </ul>
     <details>
		<ul>
        <li>Structure of the talk as follows:</li>
        <li>First generally introduce the MORSE project and give a little example of it use, </li>
        <li>... then Pierrick will show you some more details and talk about HRI and distributed simulations.</li>
		</ul>
    </details>
</section>

<section>
    <h2>Presentation outline</h2>
    <ul>
      <li>The MORSE simulator
		<ul>
      		<li>Simulating with MORSE
      		<li>MORSE Principles
      		<li>Human-Robot Interaction
      		<li>Distributed simulations
      		<li>Still missing...
		</ul>
	  <li style="color: grey;">Expectations for Human Robot Interaction
		<!--ul>
			<li>A General Framework for expectations
			<li>Simulated Application Scenarios
			<li>Low Cost Activity Recognition
			<li>Real World Application 
		</ul-->
	  <li style="color: grey;">Student Project: HRI Interface for B21
    </ul>
     <details>
		<ul>
        <li>Structure of the talk as follows:</li>
        <li>First generally introduce the MORSE project and give a little example of it use, </li>
        <li>... then Pierrick will show you some more details and talk about HRI and distributed simulations.</li>
		</ul>
    </details>
</section>

<section>
    <h2>The MORSE project</h2>
    <ul>
      <li>100% open-source, permissive BSD-like license
      <li>Release 1.0 in Feb. 2013
      <li>~30K LOC, mostly Python
    </ul>
</section>

<section>
    <h2>The MORSE community</h2>
    <ul>
      <li>Academic project, baked by academics
      <li>Initiated at LAAS-CNRS in 2009
      <li>As of Apr. 2013, contributions by 12 institutions worldwide
      <img style="width:100%" src="../media/logos/contributors.svg"/>
    </ul>
    
    <details>
		<ul>
        <li>MORSE evolved out of academics and was started in 2009 by LAAS CNRS in Toulouse...</li>
        <li>... and as for now includes ... </li>
		</ul>
    </details>
</section>

<section>
    <h2>The MORSE community</h2>
    <ul>
      <li>15 different individual contributors for the last releases
      <li>> 630 commits in 2013 only
      <li>> 130 users on <tt>morse-users</tt>
      <li> ... + the Blender and Bullet communities!
    </ul>
</section>

<section>
    <h2>Blender Game Engine + Bullet</h2>

        <video style="position:absolute;top:150px; left:50px;width:260px" src="../media/videos/bge-bathroom.webm"></video>
        <video style="position:absolute;top:150px; right:50px;width:260px" src="../media/videos/bge-yofrankie.webm"></video>
        <video style="position:absolute;top:380px; right:250px;width:300px" src="../media/videos/bullet.webm"></video>
    <details>
        <ul>
            <li>primarily a 3D modeller
            <li>provide a 3D game engine, support shaders
            <li>Switch from the modeller to the simulation == press 'P'
            <li>BGE: written in C++, extensible in Python + logic bricks
            <li>Bullet is integrated to the BGE, state-of-the art open-source library
            <li>support for rigid bodies and soft bodies simulation
            <li>limited support for dynamics (Vehicle class)
    </ul>
    </details>
</section>


<section>
	<h2>Possibility to Exchange Physics Engine</h2>
	 <video style="position:absolute;top:170px; left:50px;width:320px" src="../media/videos/grasp_bullet.webm"></video>
	 <video style="position:absolute;top:170px; left:400px;width: 320px;" src="../media/videos/grasp_dvc3d.webm"></video>
		<div style="position:absolute;top:360px; left:400px;width: 320px; text-align: center;">DVC3D</div>
		<div style="position:absolute;top:360px; left:50px;width: 320px; text-align: center;">Bullet</div>
		<div style="position:absolute;top:420px; left:50px;width: 720px;">Abstract API layer between Blender and its Physics Engine offers possibility of adding different physics engines (ODE, DVC3D, ...).</div>
</section>


<section>
	<h2>MORSE specific features</h2>
	<ul>
		<li>Adjustable degree of realism</li>
		<li>Human avatar for HRI scenarios</li>
		<li>Completely scriptable via Python</li>
		<li>Blender for modeling</li>
		<li>Bullet physics engine</li>
		<li>Middleware independence</li>
		<li>Distributed multi-node simulation</li>
	</ul>
	<details>
		<ul>
			<li>ROS users know Gazebo, and while Gazebo is a great simulator, there are also good reasons to take a closer look at MORSE!</li>
			<li>Explain why I use MORSE: Human component, High-level sensors make it easy to test high-level resoning 
			algorithms whithout dealing too much with low-level components (perception etc.)</li>
			<li>High-level sensors: If you don't want to deal with navigation, use waypoint actuator, if you want to skip perception, 
			use semantic camera</li>
			<li>+ other avantages</li>
		</ul>
	</details>
</section>

<section>
	<h2>MORSE specific features</h2>
	<ul>
		<li><strong>Adjustable degree of realism</strong></li>
		<li><strong>Human avatar for HRI scenarios</strong></li>
		<li>Completely scriptable via Python</li>
		<li>Blender for modeling</li>
		<li>Bullet physics engine</li>
		<li>Middleware independence</li>
		<li>Distributed multi-node simulation</li>
	</ul>
	<details>
		<ul>
			<li>ROS users know Gazebo, and while Gazebo is a great simulator, there are also good reasons to take a closer look at MORSE!</li>
			<li>Explain why I use MORSE: Human component, High-level sensors make it easy to test high-level resoning 
			algorithms whithout dealing too much with low-level components (perception etc.)</li>
			<li>High-level sensors: If you don't want to deal with navigation, use waypoint actuator, if you want to skip perception, 
			use semantic camera</li>
			<li>+ other avantages</li>
		</ul>
	</details>
</section>

<section>
<h2>
<pre>
$ vim pr2_kitchen/defaults.py
</pre>
</h2>
<br/>
<div>


<pre class="prettyprint">
from morse.builder import *

robot = BasePR2() # Bare PR2 model
robot.add_default_interface('ros') # control PR2 via ROS

odometry = Odometry() # Sensor for Odometry information
odometry.add_interface('ros', topic="/odom")
robot.append(odometry)

keyboard = Keyboard() # Keyboard control
robot.append(keyboard)

scan = Hokuyo() # Hokuyo 2D laser scanner
scan.translate(x=0.275, z=0.252)
scan.add_interface('ros', topic='/scan')
robot.append(scan)

env = Environment("kitchen.blend") # load custom 3d model
</pre>
</div>
	<details>
		<ul>
			<li>In the auomatically generated defaults.py file, we can define our simulation scenario...</li>
			<li>In the first 2 lines: PR2 + ROS</li>
			<li>Odemetry sensor + keyboard control (mention PR2_keyboard_teleop)</li>
			<li>Custom 3 model of the env (in this case blender, but 3D Studio etc. also possbile via Blender import)</li>
		</ul>
	</details>
</section>

<section>
<h2>
<pre>
$ morse run pr2_kitchen
</pre>
</h2>
<div>
	<video muted style="position:absolute;top:150px; left:0px; width: 100%;" src="../media/videos/pr2_mapping.webm"></video> 
<!--img style="width:100%" src="../media/images/pr2_mapping.png"-->
</div>
<reference><em>Using standard ROS <tt>robot_state_publisher</tt> and <tt>gmapping</tt></em></reference>
</section>

<section>
<h2>Navigation using move_base and AMCL localization</h2>
<br/>
<br/>
<pre class="prettyprint">
[...]	
motion = MotionXYW() # Motion controller
motion.add_interface('ros', topic='/cmd_vel')
robot.append(motion)
[...]
</pre>
<br />
<br />
<br />
</section>

<section>
<h2>
<pre>
$ morse run pr2_kitchen
</pre>
</h2>
<div>
<video muted style="position:absolute;top:150px; left:0px; width: 100%;" src="../media/videos/pr2_move_base_wide.webm#t=3"></video> 
</div>
</section>

<!--section>
<h3>MORSE Principles: Components</h3>
<ul class="incremental">
    <li>MORSE simulations are made of <i>components</i>
<li>Base components are <b>sensors</b>, <b>actuators</b> and <b>robots</b>
<li>They can be linked to <b>interfaces</b>, <b>modifiers</b> and <b>overlays</b>
<li>They are defined by a mandatory Python description
<li>They optionally come with a (Blender) 3D mesh
</ul>
</section-->

<section>
	<h3>Available Robot Components</h3>
    <ul>
		<li>14 robots
		<li>24 sensors
		<li>21 actuators
		<li>2 human components
	</ul>
	<img style="position:absolute;top:350px;left: 120px; width: 70%;" src="../media/images/all_components_3rows.png"/>
	
<details>
A click on the image redirect to MORSE Component Library in the on-line doc.<br/>

Scroll there to quickly show the available components.
</details>
</section>



<section>
    <h3>MORSE Principles: Inner loop</h3>
    <ul style="font-size:0.8em">
        <li>2 interactions modalities: <b>datastreams</b> and <b>services</b>,
        <li>datastreams: <b>published</b> by MORSE for sensors, <b>read</b> for actuators,
        <li><b>strong decoupling</b>: components are <b>not aware</b> of surrounding interfaces/modifiers,
        <li><b>modifiers</b> alter the sensors/actuators data, typically to add noise,
        <li>components' <i>local data</i> are exported/imported by <b>external interfaces</b> like sockets or ROS
        <li>services: RPC-style interaction, can be <b>synchronous</b> or <b>asynchronous</b>
    </ul>
<details>
- <a href="../media/images/main_loop.svg">main_loop.svg</a>
</details>
</section>

<section>
    <h3>MORSE Principles: Interfaces</h3>
    <ul style="font-size:0.8em">
        <li>Generic: <em>sockets</em>, <em>text</em>,
        <li>Specific to robotics: <em>middlewares</em>
            <ul>
            <li><img style="height: 21px; margin-bottom: -5px;" src="../media/images/logo-ros.png" />
            <li><img style="height: 21px; margin-bottom: -5px;" src="../media/images/logo-yarp.png" />
            <li>GenoM/Pocolibs
            <li>OpenRTM
            <li>MOOS
            </ul>
        <li>Mapping to interaction semantics: <em>RPC-oriented</em> or <em>datastream-oriented</em>
        <li>Language <em>bindings</em> available for Python. Easy to develop for other languages through the socket interface.
        <li>Simulation <b>introspection</b> possible through sockets interface
    </ul>
<details>
<ul>
    <li>ROS: well, you know... // YARP: Yet Another Robot Platform
    <li>GenoM/pocolibs: Generator of Modules and its communication layer, developed at LAAS
    <li>OpenRTM: Open source Robotic Technology Middleware, developed by Japan's National Institute of Advanced Industrial Science and Technology
    <li>MOOS: Mission Oriented Software Suite, developed at Oxford University
    <li>MORSE is middleware independant ! (bindings are modules)
</ul>
</details>
</section>

<section> 
	<h2>Goals for simulated HRI Interface</h2>
	<ul>
		<li><strong>Intuitive</strong> Interface
		<li>Controllable via <strong>Keyboard and Mouse</strong> (or Kinect)
		<li>Enable <strong>pick- and place</strong> actions, support switches
		<li><strong>Realistic</strong> postures and actions
		<li>Simulated full body <strong>motion tracking</strong>
	</ul>
	<details>
    <ul>
        <li>Control similar to 3D Computer games (Mouse for direction, keyboard for moving)
		<li>3rd person view behind avtar for movement, first person view for object interactions
		<li>interactive environment, coded with Blender BGE logic bricks
		<li>Objects placement using Blender Internal IK (ITasc)
		<li>Simulated object recognition using MORSE "semantic camera" and ROS TF   
    </ul>
    </details>
</section>

<section>
    <figure>
        <video style="left:0px" src="../media/videos/hri.webm"></video> 
        <!--figcaption style="color:white">Human-Robot interaction</figcaption-->
    </figure>
</section>

<section>
    <h3>Distributed Multi-Node Multi-Robot Simulation</h3>
    <video muted style="left:0px;width:800px" src="../media/videos/morse_multi.webm#t=15"></video>
<details>
<ul>
    <li>Two MORSE instance running and a "multinode-server"
    <li>Each robot is controlled by a node
    <li>Tested with 10 nodes (needs to work on sync : WIP)
</ul>
</details>
</section>

<section>
    <h2>Still missing...</h2>

    <ul>
        <li>Faster-than-realtime simulation</li>
        <li>Explicit <em>timeline of events</em></li>
        <li>Formal support for logging/replay</li>
        <!--li>Full support of PR2</li-->
		<li>Force/torque sensores
        <li>...(you name it!)</li>
    </ul>
</section>

<section>
    <h2>Presentation outline</h2>
    <ul>
      <li style="color:grey;">The MORSE simulator
		<!--ul>
      		<li>Simulating with MORSE
      		<li>MORSE Principles
      		<li>Human-Robot Interaction
      		<li>Distributed simulations
      		<li>Still missing...
		</ul-->
	  <li>Low Cost Activity Recognition
		<ul>
			<li>Goals
			<li>Models of Human Activities
			<li>HHMM-based Activity Recognition
			<li>Video: Real World Application 
		</ul>
	  <li style="color:grey;">Student Project: HRI Interface for B21
    </ul>
     <details>
		<ul>
        <li>So far for the MORSE simulator, in the next 10 minutes, I want to give you a general overview about what I have done during my PhD except for working on the simulator</li>
		</ul>
    </details>
</section>

<section>
	<h2>Low Cost Activity Recognition</h2>
		<!--ul>
			<li>Scenario: Robots working together with humans in domestic environments
			<li>Goal: Include models of human activities into robot planning
			<li>Human Motion tracking using Kinect sensors 
		</ul-->	
		<div style="text-align: center;">
		<img style="position:absolute;top:220px; left:145px; width: 80%;" src="../media/images/intro_1.png"/>
		</div>	
		 <details>
			<ul>
	        <li>Das Bild hier zeigt ganz gut, was wir uns als Ziel gesetzt haben</li>
			<li>Activity Recognition für Roboter in Alltagssituationen (Bild)</li>
			<li>Basierend auf Motion tracking Daten von Kinect</li> 
			</ul>
	    </details>
</section>

<section>
<h2>Goals</h2>
<ul>
	<li>Robot should be aware of human task execution to enable more human aware and adaptive planning</li>
	<li>Inexpensive and unobtrusive sensor setup</li>
	<li>Simple and noise-resistant features</li>
	<li>Anticipate likely future activities</li>
</ul>	
</section>

<section>
	<h2>Models of Human Activities</h2>
	<ul>
		<li><strong>Spatial model</strong> representing regions where humans generally are located during pick- and place tasks</li>
		<!--li>Use High-Level Hierarchical HMM to perform Activity Recognition observing human task performance</li-->
		
			<img style="position:absolute;top:350px; left:100px; width: 30%;" src="../media/images/SPRAM_data_overview.png"/>
			<img style="position:absolute;top:375px; left:420px; width: 30%;" src="../media/images/full_spatial_model_1.png"/>
	</ul>
</section>

<section>
	<h2>HHMM-based Activity Recognition</h2>
		<div style="position:absolute;top:180px; left:50px;width: 720px;">Generate high-Level <strong>hierarchical HMM (HHMM)</strong> to perform activity recognition observing human task performance</div>
			<img style="position:absolute;top:280px; left:150px; width: 70%;" src="../media/images/hhmm.png"/>

</section>

<section>
	<h2>HHMM-based Activity Recognition</h2>
	<figure>
	    <video muted style="left:0px" src="../media/videos/LoCoAcRe_sml.webm"></video> 
	</figure>
</section>

<section>
    <h2>Presentation outline</h2>
    <ul>
      <li style="color:grey;">The MORSE simulator
		<!--ul>
      		<li>Simulating with MORSE
      		<li>MORSE Principles
      		<li>Human-Robot Interaction
      		<li>Distributed simulations
      		<li>Still missing...
		</ul-->
	  <li style="color:grey;">Low Cost Activity Recognition
		<!--ul>
			<li>Low Cost Activity Recognition
			<li>A General Framework for expectations
			<li>Simulated Application Scenarios
			<li>Real World Application 
		</ul-->
	  <li>Student Project: HRI Interface for B21
    </ul>
     <details>
		<ul>
        <li>As a last example, show student project...</li>
		</ul>
    </details>
</section>

<section>
	<h2>Goals</h2>
	<ul>
		<li>GUI for Robot control via natural language
		<li>Selection of Speech Recognition (pocketsphinx VS Google)
		<li>Grammatical analysis of commands	
		<li>Interface to knowledge base (KnowRob)
		<li>Include (Emergency) Stop of robot
	</ul>
</section>


<section>
<figure>
    <video muted style="left:0px" src="../media/videos/hri_interface_720p.webm"></video> 
</figure>
</section>


<section>
<h2>Other Projects</h2>
	<ul>
		<li>Learning Models of human activities
		<li>Motion tracking dataset about human morning routine
		<li>Expectations Framework for human-aware, reactive planning
		<li>Multi floor Graph-based SLAM
	</ul>	
	<img style="position:absolute;top:440px; left:40px; height: 18%;" src="../media/images/clustering.png"/>
	<img style="position:absolute;top:440px; left:192px; height: 18%;" src="../media/images/dataset.png"/>
	<img style="position:absolute;top:440px; left:320px; height: 18%;" src="../media/images/jido_confused.png"/>
	<img style="position:absolute;top:440px; left:450px; height: 18%;" src="../media/images/multi_floor_slam_1.png"/>
	<img style="position:absolute;top:440px; left:620px; height: 18%;" src="../media/images/multi_floor_slam_2.png"/>

</section>

<section id='end'>
    <h2>Questions?</h2>
	<img align="center" style="position:absolute;top:30%; left:270px; height: 40%;" src="../media/images/qrcode_hcai.png"/>
	<h3 style="position:absolute;top: 400px;">http://hcai.in.tum.de/members/kargm</h3>
</section>

<!-- Your Style -->
<!-- Define the style of your presentation -->

<script>
//$("img#taxonomy").axzoomer({
//    'maxZoom':4
//    });
//$("img#taxonomy").smoothZoom({
//    width:800,
//    height:600,
//    border_SIZE:0});
</script>

<!-- Maybe a font from http://www.google.com/webfonts ? -->
<!--<link href='http://fonts.googleapis.com/css?family=Actor' rel='stylesheet'>-->

<link href='parser.css' rel='stylesheet'>

<style>
    @font-face {
    font-family: 'Lato';
    font-style: normal;
    font-weight: 400;
    src: url('Lato.ttf');
    }

  html, .view body { background-color: black; counter-reset: slideidx; }
  /*For the printout: html, .view body { background-color: white; counter-reset: slideidx; }*/
  body, .view section { background-color: white; border-radius: 12px }
  /*For the printout: body, .view section { background-color: white; border:2px solid black;border-radius: 12px;}*/
  /* A section is a slide. It's size is 800x600, and this will never change */
  section, .view head > title {
      /* The font from Google */
      font-family: 'Lato', arial, serif;
      font-size: 30px;
  }

  .view section:after {
    counter-increment: slideidx;
    content: counter(slideidx, decimal-leading-zero);
    position: absolute; bottom: -80px; right: 100px;
    color: white;
  }

  .view head > title {
    color: white;
    text-align: center;
    margin: 1em 0 1em 0;
  }

  h1, h2 {
    margin-top: 100px;
    text-align: left;
    font-size: 40px;
    margin-left: 40px;
  }
  h3 {
    margin: 50px 0 50px 100px;
  }

  ul {
      margin: 50px 150px;
  }
  ul ul {
      margin: 20px 20px;
      font-size: 0.8em;
  }


  p {
    margin: 75px;
    font-size: 50px;
}

  pre {
      font-size: 0.6em;
      margin-left: 10px;
      padding-left: 5px;
      /*border-left: 1px solid;*/
  }

  blockquote {
    height: 100%;
    background-color: black;
    color: white;
    font-size: 60px;
    padding: 50px;
  }
  blockquote:before {
    content: open-quote;
  }
  blockquote:after {
    content: close-quote;
  }

  .note {
      position:absolute;
      border-radius:5px;
      border:1px solid;
      background:rgba(255, 255, 255, 0.9);
      padding:3px;
      font-size:10px;
   }
  /* Figures are displayed full-page, with the caption
     on top of the image/video */
  figure {
    background-color: white;
    width: 100%;
    height: 100%;
  }
  figure > * {
    position: absolute;
  }
  figure > img, figure > video {
    top: 10%; 
    /* Set up proportionate scaling */
    width: 100%;
    height: auto;
  }
  figure.vertical > img, figure.vertical > video {
    left: 10%; 
    top:0%;
    /* Set up proportionate scaling */
    height: 100%;
    width: auto;
  }
  figcaption {
    margin: 70px;
    font-size: 30px;
  }
  fignote {
  bottom:0;
  right:0;
    margin: 70px;
    font-size: 16px;
  }

  reference {
  bottom:0;
  right:0;
  margin: 40px;
  font-size: 14px;
  position:absolute;
  }


  footer {
    position: absolute;
    bottom: 0;
    width: 100%;
    padding: 20px;
    text-align: right;
    background-color: #F3F4F8;
    border-top: 1px solid #CCC;
  }


table {
        overflow:hidden;
        border:1px solid #d3d3d3;
        background:#fefefe;
        width:70%;
        margin:5% auto 0;
        -moz-border-radius:5px; /* FF1+ */
        -webkit-border-radius:5px; /* Saf3-4 */
        border-radius:5px;
    }
    
    th, td {padding:3px 5px 3px; text-align:center; }
    
    th {padding-top:8px; background:#e8eaeb;}
    

  /* Transition effect */
  /* Feel free to change the transition effect for original
     animations. See here:
     https://developer.mozilla.org/en/CSS/CSS_transitions
     How to use CSS3 Transitions: */
  section {
    -moz-transition: left 0ms linear 0s;
    -webkit-transition: left 400ms linear 0s;
    -ms-transition: left 400ms linear 0s;
    transition: left 400ms linear 0s;
  }
  .view section {
    -moz-transition: none;
    -webkit-transition: none;
    -ms-transition: none;
    transition: none;
  }

  .view section[aria-selected] {
    border: 5px red solid;
  }

  /* Before */
  section { left: -150%; }
  /* Now */
  section[aria-selected] { left: 0; }
  /* After */
  section[aria-selected] ~ section { left: +150%; }

  /* Incremental elements */

  /* By default, visible */
  .incremental > * { opacity: 0.5; }

  /* The current item */
  .incremental > *[aria-selected] { opacity: 1; }

  /* The items to-be-selected */
  .incremental > *[aria-selected] ~ * { opacity: 0; }

  /* The progressbar, at the bottom of the slides, show the global
     progress of the presentation. */
  #progress-bar {
    font-family: 'Actor', arial, serif;
    height: 25px;
    /*background: #AAA;*/
  }
</style>

<!-- {{{{ dzslides core
#
#
#     __  __  __       .  __   ___  __
#    |  \  / /__` |    | |  \ |__  /__`
#    |__/ /_ .__/ |___ | |__/ |___ .__/ core :€
#
#
# The following block of code is not supposed to be edited.
# But if you want to change the behavior of these slides,
# feel free to hack it!
#
-->

<div id="progress-bar"></div>

<!-- Default Style -->
<style>
  * { margin: 0; padding: 0; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; box-sizing: border-box; }
  details { display: none; }
  body {
    width: 800px; height: 600px;
    margin-left: -400px; margin-top: -300px;
    position: absolute; top: 50%; left: 50%;
    overflow: hidden;
    display: none;
  }
  .view body {
    position: static;
    margin: 0; padding: 0;
    width: 100%; height: 100%;
    display: inline-block;
    overflow: visible; overflow-x: hidden;
    /* undo Dz.onresize */
    transform: none !important;
    -moz-transform: none !important;
    -webkit-transform: none !important;
    -o-transform: none !important;
    -ms-transform: none !important;
  }
  .view head, .view head > title { display: block }
  section {
    position: absolute;
    pointer-events: none;
    width: 100%; height: 100%;
  }
  .view section {
    pointer-events: auto;
    position: static;
    width: 800px; height: 600px;
    margin: -150px -200px;
    float: left;

    transform: scale(.4);
    -moz-transform: scale(.4);
    -webkit-transform: scale(.4);
    -o-transform: scale(.4);
    -ms-transform: scale(.4);
  }
  .view section > * { pointer-events: none; }
  section[aria-selected] { pointer-events: auto; }
  html { overflow: hidden; }
  html.view { overflow: visible; }
  body.loaded { display: block; }
  .incremental {visibility: hidden; }
  .incremental[active] {visibility: visible; }
  #progress-bar{
    bottom: 0;
    position: absolute;
    width:50px;
    right: 0;
    -moz-transition: width 400ms linear 0s;
    -webkit-transition: width 400ms linear 0s;
    -ms-transition: width 400ms linear 0s;
    transition: width 400ms linear 0s;
  }
  .view #progress-bar {
    display: none;
  }
</style>

<script>
  var Dz = {
    remoteWindows: [],
    idx: -1,
    step: 0,
    html: null,
    slides: null,
    progressBar : null,
    params: {
      autoplay: "1"
    }
  };

  Dz.init = function() {
    document.body.className = "loaded";
    this.slides = Array.prototype.slice.call($$$$("body > section"));
    this.endslide = $$$("#end");
    this.endidx = this.slides.indexOf(this.endslide);
    this.progressBar = $$$("#progress-bar");
    this.html = document.body.parentNode;
    this.setupParams();
    this.onhashchange();
    this.setupTouchEvents();
    this.onresize();
    this.setupView();
  }

  Dz.setupParams = function() {
    var p = window.location.search.substr(1).split('&');
    p.forEach(function(e, i, a) {
      var keyVal = e.split('=');
      Dz.params[keyVal[0]] = decodeURIComponent(keyVal[1]);
    });
  // Specific params handling
    if (!+this.params.autoplay)
      $$$$.forEach($$$$("video"), function(v){ v.controls = true });
  }

  Dz.onkeydown = function(aEvent) {
    // Don't intercept keyboard shortcuts
    if (aEvent.altKey
      || aEvent.ctrlKey
      || aEvent.metaKey
      || aEvent.shiftKey) {
      return;
    }
    if ( aEvent.keyCode == 37 // left arrow
      || aEvent.keyCode == 38 // up arrow
      || aEvent.keyCode == 33 // page up
    ) {
      aEvent.preventDefault();
      this.back();
    }
    if ( aEvent.keyCode == 39 // right arrow
      || aEvent.keyCode == 40 // down arrow
      || aEvent.keyCode == 34 // page down
    ) {
      aEvent.preventDefault();
      this.forward();
    }
    if (aEvent.keyCode == 35) { // end
      aEvent.preventDefault();
      this.goEnd();
    }
    if (aEvent.keyCode == 36) { // home
      aEvent.preventDefault();
      this.goStart();
    }
    if (aEvent.keyCode == 32) { // space
      aEvent.preventDefault();
      this.toggleContent();
    }
    if (aEvent.keyCode == 70) { // f
      aEvent.preventDefault();
      this.goFullscreen();
    }
    if (aEvent.keyCode == 79) { // o
      aEvent.preventDefault();
      this.toggleView();
    }
  }

  /* Touch Events */

  Dz.setupTouchEvents = function() {
    var orgX, newX;
    var tracking = false;

    var db = document.body;
    db.addEventListener("touchstart", start.bind(this), false);
    db.addEventListener("touchmove", move.bind(this), false);

    function start(aEvent) {
      aEvent.preventDefault();
      tracking = true;
      orgX = aEvent.changedTouches[0].pageX;
    }

    function move(aEvent) {
      if (!tracking) return;
      newX = aEvent.changedTouches[0].pageX;
      if (orgX - newX > 100) {
        tracking = false;
        this.forward();
      } else {
        if (orgX - newX < -100) {
          tracking = false;
          this.back();
        }
      }
    }
  }

  Dz.setupView = function() {
    document.body.addEventListener("click", function ( e ) {
      if (!Dz.html.classList.contains("view")) return;
      if (!e.target || e.target.nodeName != "SECTION") return;

      Dz.html.classList.remove("view");
      Dz.setCursor(Dz.slides.indexOf(e.target) + 1);
    }, false);
  }

  /* Adapt the size of the slides to the window */

  Dz.onresize = function() {
    var db = document.body;
    var sx = db.clientWidth / window.innerWidth;
    var sy = db.clientHeight / window.innerHeight;
    var transform = "scale(" + (1/Math.max(sx, sy)) + ")";

    db.style.MozTransform = transform;
    db.style.WebkitTransform = transform;
    db.style.OTransform = transform;
    db.style.msTransform = transform;
    db.style.transform = transform;
  }


  Dz.getDetails = function(aIdx) {
    var s = $$$("section:nth-of-type(" + aIdx + ")");
    var d = s.$$$("details");
    return d ? d.innerHTML : "";
  }

  Dz.onmessage = function(aEvent) {
    var argv = aEvent.data.split(" "), argc = argv.length;
    argv.forEach(function(e, i, a) { a[i] = decodeURIComponent(e) });
    var win = aEvent.source;
    if (argv[0] === "REGISTER" && argc === 1) {
      this.remoteWindows.push(win);
      this.postMsg(win, "REGISTERED", document.title, this.slides.length);
      this.postMsg(win, "CURSOR", this.idx + "." + this.step);
      return;
    }
    if (argv[0] === "BACK" && argc === 1)
      this.back();
    if (argv[0] === "FORWARD" && argc === 1)
      this.forward();
    if (argv[0] === "START" && argc === 1)
      this.goStart();
    if (argv[0] === "END" && argc === 1)
      this.goEnd();
    if (argv[0] === "TOGGLE_CONTENT" && argc === 1)
      this.toggleContent();
    if (argv[0] === "SET_CURSOR" && argc === 2)
      window.location.hash = "#" + argv[1];
    if (argv[0] === "GET_CURSOR" && argc === 1)
      this.postMsg(win, "CURSOR", this.idx + "." + this.step);
    if (argv[0] === "GET_NOTES" && argc === 1)
      this.postMsg(win, "NOTES", this.getDetails(this.idx));
  }

  Dz.toggleContent = function() {
    // If a Video is present in this new slide, play it.
    // If a Video is present in the previous slide, stop it.
    var s = $$$("section[aria-selected]");
    if (s) {
      var video = s.$$$("video");
      if (video) {
        if (video.ended || video.paused) {
          video.play();
        } else {
          video.pause();
        }
      }
    }
  }

  Dz.setCursor = function(aIdx, aStep) {
    // If the user change the slide number in the URL bar, jump
    // to this slide.
    aStep = (aStep != 0 && typeof aStep !== "undefined") ? "." + aStep : ".0";
    window.location.hash = "#" + aIdx + aStep;
  }

  Dz.onhashchange = function() {
    var cursor = window.location.hash.split("#"),
        newidx = 1,
        newstep = 0;
    if (cursor.length == 2) {
      newidx = ~~cursor[1].split(".")[0];
      newstep = ~~cursor[1].split(".")[1];
      if (newstep > Dz.slides[newidx - 1].$$$$('.incremental > *').length) {
        newstep = 0;
        newidx++;
      }
    }
    this.setProgress(newidx, newstep);
    if (newidx != this.idx) {
      this.setSlide(newidx);
    }
    if (newstep != this.step) {
      this.setIncremental(newstep);
    }
    for (var i = 0; i < this.remoteWindows.length; i++) {
      this.postMsg(this.remoteWindows[i], "CURSOR", this.idx + "." + this.step);
    }
  }

  Dz.back = function() {
    if (this.idx == 1 && this.step == 0) {
      return;
    }
    if (this.step == 0) {
      this.setCursor(this.idx - 1,
                     this.slides[this.idx - 2].$$$$('.incremental > *').length);
    } else {
      this.setCursor(this.idx, this.step - 1);
    }
  }

  Dz.forward = function() {
    if (this.idx >= this.slides.length &&
        this.step >= this.slides[this.idx - 1].$$$$('.incremental > *').length) {
        return;
    }
    if (this.step >= this.slides[this.idx - 1].$$$$('.incremental > *').length) {
      this.setCursor(this.idx + 1, 0);
    } else {
      this.setCursor(this.idx, this.step + 1);
    }
  }

  Dz.goStart = function() {
    this.setCursor(1, 0);
  }

  Dz.goEnd = function() {
    var lastIdx = this.slides.length;
    var lastStep = this.slides[lastIdx - 1].$$$$('.incremental > *').length;
    this.setCursor(lastIdx, lastStep);
  }

  Dz.toggleView = function() {
    this.html.classList.toggle("view");

    if (this.html.classList.contains("view")) {
      $$$("section[aria-selected]").scrollIntoView(true);
    }
  }

  Dz.setSlide = function(aIdx) {
    this.idx = aIdx;
    var old = $$$("section[aria-selected]");
    var next = $$$("section:nth-of-type("+ this.idx +")");
    if (old) {
      old.removeAttribute("aria-selected");
      var videos = old.$$$$("video");
      for (var i = 0 ; i < videos.length; i++) {
        videos[i].pause();
      }
    }
    if (next) {
      next.setAttribute("aria-selected", "true");
      if (this.html.classList.contains("view")) {
        next.scrollIntoView();
      }
      var videos = next.$$$$("video");
      for (var i = 0 ; i < videos.length; i++) {
      
        if (videos[i] && !!+this.params.autoplay) {
         videos[i].play();
        }
      }
    } else {
      // That should not happen
      this.idx = -1;
      // console.warn("Slide doesn't exist.");
    }
  }

  Dz.setIncremental = function(aStep) {
    this.step = aStep;
    var old = this.slides[this.idx - 1].$$$('.incremental > *[aria-selected]');
    if (old) {
      old.removeAttribute('aria-selected');
    }
    var incrementals = $$$$('.incremental');
    if (this.step <= 0) {
      $$$$.forEach(incrementals, function(aNode) {
        aNode.removeAttribute('active');
      });
      return;
    }
    var next = this.slides[this.idx - 1].$$$$('.incremental > *')[this.step - 1];
    if (next) {
      next.setAttribute('aria-selected', true);
      next.parentNode.setAttribute('active', true);
      var found = false;
      $$$$.forEach(incrementals, function(aNode) {
        if (aNode != next.parentNode)
          if (found)
            aNode.removeAttribute('active');
          else
            aNode.setAttribute('active', true);
        else
          found = true;
      });
    } else {
      setCursor(this.idx, 0);
    }
    return next;
  }

  Dz.goFullscreen = function() {
    var html = $$$('html'),
        requestFullscreen = html.requestFullscreen || html.requestFullScreen || html.mozRequestFullScreen || html.webkitRequestFullScreen;
    if (requestFullscreen) {
      requestFullscreen.apply(html);
    }
  }
  
  Dz.setProgress = function(aIdx, aStep) {
    var slide = $$$("section:nth-of-type("+ aIdx +")");
    if (!slide)
      return;
    var steps = slide.$$$$('.incremental > *').length + 1,
        slideSize = 100 / (this.slides.length - 1),
        stepSize = slideSize / steps;
        //this.progressBar.style.width = ((aIdx - 1) * slideSize + aStep * stepSize) + '%';
    if (aIdx == 1) // no numbering on first slide
        this.progressBar.innerHTML = "";
    else
        this.progressBar.innerHTML = (aIdx - 1) + "/" + this.endidx;
  }
  
  Dz.postMsg = function(aWin, aMsg) { // [arg0, [arg1...]]
    aMsg = [aMsg];
    for (var i = 2; i < arguments.length; i++)
      aMsg.push(encodeURIComponent(arguments[i]));
    aWin.postMessage(aMsg.join(" "), "*");
  }

  function init() {
    Dz.init();
    window.onkeydown = Dz.onkeydown.bind(Dz);
    window.onresize = Dz.onresize.bind(Dz);
    window.onhashchange = Dz.onhashchange.bind(Dz);
    window.onmessage = Dz.onmessage.bind(Dz);

    prettyPrint()
  }

  window.onload = init;
</script>


<script> // Helpers
  if (!Function.prototype.bind) {
    Function.prototype.bind = function (oThis) {

      // closest thing possible to the ECMAScript 5 internal IsCallable
      // function 
      if (typeof this !== "function")
      throw new TypeError(
        "Function.prototype.bind - what is trying to be fBound is not callable"
      );

      var aArgs = Array.prototype.slice.call(arguments, 1),
          fToBind = this,
          fNOP = function () {},
          fBound = function () {
            return fToBind.apply( this instanceof fNOP ? this : oThis || window,
                   aArgs.concat(Array.prototype.slice.call(arguments)));
          };

      fNOP.prototype = this.prototype;
      fBound.prototype = new fNOP();

      return fBound;
    };
  }

  var $$$ = (HTMLElement.prototype.$$$ = function(aQuery) {
    return this.querySelector(aQuery);
  }).bind(document);

  var $$$$ = (HTMLElement.prototype.$$$$ = function(aQuery) {
    return this.querySelectorAll(aQuery);
  }).bind(document);

  $$$$.forEach = function(nodeList, fun) {
    Array.prototype.forEach.call(nodeList, fun);
  }

</script>
<!-- vim: set fdm=marker: }}} -->

